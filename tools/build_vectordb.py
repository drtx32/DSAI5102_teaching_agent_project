import os
import asyncio
import fitz  # PyMuPDF
from pathlib import Path
from tqdm.asyncio import tqdm
import multiprocessing
from typing import List

from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

os.chdir(Path(__file__).parent.parent)
print(f"Current working directory: {os.getcwd()}")


# -----------------------------
# ğŸ”¹ 1. å¼‚æ­¥è¯»å– PDF
# -----------------------------
async def read_pdf_async(pdf_path: str) -> str:
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, read_pdf_sync, pdf_path)


def read_pdf_sync(pdf_path: str) -> str:
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text


# -----------------------------
# ğŸ”¹ 2. å¼‚æ­¥ç”Ÿæˆ Embedding
# -----------------------------
async def embed_batch(
    texts: List[str],
    model: OllamaEmbeddings,
    sem: asyncio.Semaphore,
    pbar: tqdm
):
    """åˆ©ç”¨å¹¶å‘ç”Ÿæˆ embedding"""
    async with sem:   # é™åˆ¶å¹¶è¡Œåº¦
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, model.embed_documents, texts)
        pbar.update(len(texts))
        return result


# -----------------------------
# ğŸ”¹ 3. ä¸»æµç¨‹ï¼šå¤šä¸ª PDF â†’ æ–‡æœ¬ â†’ Embedding â†’ FAISS
# -----------------------------
async def build_faiss_from_pdfs(pdf_paths: List[str], faiss_path: str):
    print(f"ğŸ“„ å…± {len(pdf_paths)} ä¸ª PDF æ–‡ä»¶")

    if len(pdf_paths) == 0:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶!")
        return

    # ------------------------
    # Step 1: å¼‚æ­¥è¯»å–å…¨éƒ¨ PDF
    # ------------------------
    print("ğŸ“˜ æ­£åœ¨è¯»å– PDF ...")
    pdf_tasks = [read_pdf_async(p) for p in pdf_paths]
    pdf_texts = await tqdm.gather(*pdf_tasks)
    print("ğŸ“˜ PDF è¯»å–å®Œæˆ\n")

    # ------------------------
    # Step 2: æ‹†åˆ†æ–‡æœ¬ï¼ˆæŒ‰æ®µè½ï¼‰
    # ------------------------
    docs = []
    for pdf_text in pdf_texts:
        parts = [p.strip() for p in pdf_text.split("\n") if p.strip()]
        docs.extend(parts)

    print(f"âœ‚ï¸ æ€»æ–‡æœ¬æ®µè½æ•°é‡ï¼š {len(docs)}")

    # ------------------------
    # Step 3: å¹¶å‘ embedding
    # ------------------------
    embed_model = OllamaEmbeddings(model="nomic-embed-text")

    # è‡ªåŠ¨å¹¶è¡Œåº¦ = CPU æ ¸æ•°
    max_workers = multiprocessing.cpu_count()
    sem = asyncio.Semaphore(max_workers)

    print(f"âš¡ å¼€å§‹ç”Ÿæˆ embeddingsï¼ˆå¹¶è¡Œåº¦ = {max_workers}ï¼‰")

    # ä½ å¯ä»¥è°ƒèŠ‚ chunk_sizeï¼Œè¿™é‡Œé»˜è®¤ 32 è¡Œä¸€ä¸ª batch
    chunk_size = 32
    chunks = [docs[i:i + chunk_size] for i in range(0, len(docs), chunk_size)]

    pbar = tqdm(total=len(docs), desc="Embedding")

    embed_tasks = [
        embed_batch(chunk, embed_model, sem, pbar)
        for chunk in chunks
    ]

    all_vectors_nested = await tqdm.gather(*embed_tasks)
    all_vectors = [v for batch in all_vectors_nested for v in batch]  # flatten
    pbar.close()

    print("âš¡ Embeddings ç”Ÿæˆå®Œæ¯•\n")

    # ------------------------
    # Step 4: å»ºç«‹ FAISS
    # ------------------------
    print("ğŸ§± æ­£åœ¨æ„å»º FAISS index ...")
    # FAISS.from_embeddings éœ€è¦ (text, embedding) çš„å…ƒç»„åˆ—è¡¨
    text_embedding_pairs = list(zip(docs, all_vectors))
    faiss_store = FAISS.from_embeddings(
        text_embeddings=text_embedding_pairs,
        embedding=embed_model
    )

    faiss_store.save_local(faiss_path)
    print(f"ğŸ“¦ FAISS å·²ä¿å­˜åˆ°ï¼š{faiss_path}")


# -----------------------------
# ğŸ”¹ ä¸»å…¥å£ï¼ˆå¤–éƒ¨è°ƒç”¨ï¼‰
# -----------------------------
def build(pdf_paths: List[str], faiss_path="faiss_index"):
    asyncio.run(build_faiss_from_pdfs(pdf_paths, faiss_path))


# -----------------------------
# ğŸ”¹ è„šæœ¬è¿è¡Œ
# -----------------------------
if __name__ == "__main__":
    pdfs = list(Path("assets/pdfs").glob("*.pdf"))
    build(pdfs, "vectordb/faiss")
