import queue
import streamlit as st
from ..utils.streamlit_float import *
from ..agent.worker import SYSTEM_PROMPT, LangGraphWorker
from langchain_core.messages import AIMessage
from ..llm.llm_provider import PROVIDER_DISPLAY_NAMES


FIRST_TIME_USER_INPUT = (
    "æˆ‘çš„ä¸“ä¸šæ–¹å‘åå‘{major}, åœ¨{field}æ–¹å‘æœ‰å›°æƒ‘, å¸Œæœ›å¾—åˆ°æ‚¨çš„è§£ç­”."
    "ä»¥ä¸‹æ˜¯æˆ‘çš„é—®é¢˜:\n{question}"
)


# -----------------------------
# Chat area
# -----------------------------
@st.dialog("ğŸ’¬ AI Chat", width="large")
def ask_ai() -> None:
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(uuid.uuid4())

    if "messages" not in st.session_state:
        st.session_state.messages = [{
            "role": "assistant",
            "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„æ•°æ®ç§‘å­¦åŠ©æ•™AIï¼Œèƒ½å¤Ÿä½¿ç”¨RAGå’Œç½‘é¡µæœç´¢çš„åŠŸèƒ½ã€‚"
            "è¯·éšæ—¶å‘æˆ‘æé—®ã€‚"}]

    placeholder = st.container(height=800, border=False)

    if len(st.session_state.messages) == 1:
        majors = placeholder.pills("your major (multi-choices):", options=[
            "finance", "computer science", "biology", "chemistry", "physics",
            "mathematics", "engineering", "economics", "psychology", "sociology",
            "history", "literature", "art", "music", "philosophy"
        ], selection_mode="multi")
        fields = placeholder.pills("desired field (multi-choices):", options=[
            "fundamental principles", "data analysis knowledge",
            "algorithm application to practical analysis"
        ], selection_mode="multi")

    # Display previous messages
    for msg in st.session_state.messages:
        with placeholder.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜"):
        # åˆå§‹åŒ–åå°çº¿ç¨‹
        if len(st.session_state.get("cfg", {})) == 4 and \
                len(st.session_state.messages) == 1:
            if "worker" not in st.session_state:
                st.session_state.request_q = queue.Queue()
                st.session_state.reply_q = queue.Queue()

                cfg = st.session_state.cfg
                cfg["thread_id"] = st.session_state.thread_id

                worker = LangGraphWorker(
                    st.session_state.request_q,
                    st.session_state.reply_q,
                    cfg
                )
                worker.start()
                st.session_state.worker = worker
            st.toast("AI èŠå¤©çº¿ç¨‹å·²å¯åŠ¨")
        elif len(st.session_state.get("cfg", {})) < 4:
            st.toast("è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®æ¨¡å‹å‚æ•°ï¼Œç„¶åå†ä½¿ç”¨ AI èŠå¤©åŠŸèƒ½")

        if len(st.session_state.messages) == 1:
            prompt = FIRST_TIME_USER_INPUT.format(
                major=", ".join(majors),
                field=", ".join(fields),
                question=prompt
            )
        st.session_state.messages.append(
            {"role": "user", "content": prompt})
        with placeholder.chat_message("user"):
            st.markdown(prompt)

        # å‘é€åˆ°åå°çº¿ç¨‹
        st.session_state.request_q.put(prompt)

        # ç­‰å¾… worker å›ç­”
        with placeholder.chat_message("assistant"):
            ans_placeholder = st.empty()
            reply = st.session_state.reply_q.get()  # é˜»å¡ç­‰å¾…
            ans_placeholder.markdown(reply)

        st.session_state.messages.append(
            {"role": "assistant", "content": reply})


def ask_ai_button() -> None:
    float_init()
    float_ai_asking = st.container(width=100)
    with float_ai_asking:
        st.button("Ask AI", key="AI_asking", on_click=ask_ai,
                  type="primary", icon=":material/question_answer:")
    float_ai_asking.float(
        css="position: fixed; bottom: 20px; right: 20px; z-index: 120;")
